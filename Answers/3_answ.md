# Классификация систем

---

## Вопрос 13: Классификация систем по Флинну: SISD, SIMD, MISD и MIMD. Локальные и распределенные системы в контексте параллельных вычислений

### Классификация Флинна
Классификация архитектур вычислительных систем, предложенная Майклом Флинном в 1966 году, основана на понятии потока (последовательности команд или данных). Выделяют 4 класса:

### 1. SISD (Single Instruction, Single Data)
**Одиночный поток команд, одиночный поток данных.**
*   **Описание**: Классическая архитектура фон Неймана. В каждый момент времени один процессор выполняет одну инструкцию над одним элементом данных.
*   **Особенности**: Параллелизм отсутствует (возможен только конвейерный параллелизм внутри CPU).
*   **Примеры**: Традиционные одноядерные ПК (Intel 8086, 80486), простые микроконтроллеры.

### 2. SIMD (Single Instruction, Multiple Data)
**Одиночный поток команд, множественный поток данных.**
*   **Описание**: Одна инструкция выполняется одновременно на множестве процессорных элементов, обрабатывая разные данные.
*   **Особенности**: Синхронная параллельная обработка. Эффективно для работы с векторами, матрицами, массивами.
*   **Примеры**: Векторные процессоры, графические процессоры (GPU), матричные процессоры, расширения CPU (MMX, SSE, AVX).

### 3. MISD (Multiple Instruction, Single Data)
**Множественный поток команд, одиночный поток данных.**
*   **Описание**: Несколько процессоров выполняют разные инструкции над одним и тем же потоком данных.
*   **Особенности**: Данные передаются от одного процессора к другому (конвейерная обработка на уровне процессоров). Самый редкий тип архитектуры.
*   **Примеры**: Специализированные криптографические системы, системы отказоустойчивости (где несколько процессоров дублируют вычисления для проверки ошибок), систолические массивы.

### 4. MIMD (Multiple Instruction, Multiple Data)
**Множественный поток команд, множественный поток данных.**
*   **Описание**: Несколько независимых процессоров выполняют различные инструкции над различными данными.
*   **Особенности**: Полный асинхронный параллелизм. Самый распространенный класс современных параллельных систем.
*   **Примеры**: Многоядерные процессоры (SMP), кластеры рабочих станций, суперкомпьютеры.

---

### Локальные и распределенные системы в контексте параллельных вычислений

Параллельные системы (обычно класса MIMD) делятся на два основных типа в зависимости от организации памяти и взаимодействия:

#### 1. Локальные системы (Системы с общей памятью / Tightly Coupled)
*   **Архитектура**: Процессоры (ядра) расположены физически близко (в одном корпусе/на одной плате) и соединены высокоскоростной шиной.
*   **Память**: **Shared Memory (Общая память)**. Единое глобальное адресное пространство, доступное всем процессорам. Изменения памяти одним процессором видны другим.
*   **Взаимодействие**: Через чтение и запись общих переменных в памяти.
*   **Синхронизация**: Примитивы ОС (мьютексы, семафоры, спинлоки).
*   **Примеры**: SMP (Symmetric Multiprocessing) сервера, многоядерные CPU (Core i7, Ryzen).

#### 2. Распределенные системы (Системы с распределенной памятью / Loosely Coupled)
*   **Архитектура**: Состоит из множества автономных узлов (компьютеров), соединенных коммуникационной сетью (Ethernet, Infiniband).
*   **Память**: **Distributed Memory (Распределенная память)**. Каждый узел имеет собственную локальную память, недоступную другим напрямую.
*   **Взаимодействие**: **Message Passing (Передача сообщений)**. Обмен данными происходит через явную отправку и прием сообщений по сети (MPI, RPC, Sockets).
*   **Синхронизация**: Обмен сообщениями, барьеры.
*   **Примеры**: Кластеры (Beowulf), Grid-системы, облачные вычислительные среды.
