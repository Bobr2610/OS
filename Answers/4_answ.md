# Понятие потока

Понятие потока - продолжи ... 

---

## Вопрос 14. Причины создания потоков. Реализация сервера для обработки запросов через однопоточный процессы и множество потоков.

### Причины создания потоков

Потоки (threads) были созданы как эволюционное развитие модели процессов для решения ряда практических задач, связанных с параллелизмом и производительностью:

#### 1. **Модульность и простота кода**
- Потоки позволяют разбить приложение на логические потоки управления, каждый из которых решает отдельную задачу
- Вместо написания сложной машины состояний с обработкой событий можно использовать последовательный код в каждом потоке
- Каждый поток может быть написан в традиционном стиле последовательного программирования

#### 2. **Эффективное использование ресурсов**
- Потоки одного процесса делят одно адресное пространство и могут быстро переключаться между собой
- Переключение контекста между потоками дешевле, чем между процессами (не требуется переключение виртуального адресного пространства)
- Создание потока требует значительно меньше ресурсов, чем создание процесса

#### 3. **Параллелизм и производительность на многопроцессорных системах**
- На многоядерных системах потоки могут выполняться по-настоящему параллельно на разных ядрах
- Это позволяет использовать вычислительные ресурсы более эффективно и повысить общую производительность

#### 4. **Реагирование на блокирующие операции**
- Когда один поток выполняет блокирующую операцию (чтение с диска, сетевой запрос), другие потоки могут продолжить работу
- Это особенно важно для серверных приложений, которые должны обслуживать множество клиентов одновременно

#### 5. **Упрощение асинхронной обработки**
- Потоки естественнее моделируют асинхронные события, чем обработка через события или машины состояний

### Реализация сервера — Однопоточный подход

```
Однопоточный сервер:
┌─────────────────────────────────────────┐
│         Основной поток сервера          │
├─────────────────────────────────────────┤
│ while (true) {                          │
│   accept() → получить запрос от клиента│
│   process() → обработать запрос         │
│   send() → отправить ответ              │
│ }                                       │
└─────────────────────────────────────────┘

Проблемы:
- Обрабатывается только один клиент за раз
- Остальные клиенты ждут в очереди (очередь портов ОС)
- Если обработка занимает время, клиенты испытывают задержку
- Невозможно использовать многоядерные системы
```

**Характеристики:**
- **Преимущества:** простоту реализации, отсутствие синхронизации
- **Недостатки:** плохая масштабируемость, высокая задержка для клиентов, неэффективное использование процессорных ресурсов

### Реализация сервера — Многопоточный подход

```
Многопоточный сервер:

┌──────────────────────────────────────┐
│     Главный поток приемщика          │
├──────────────────────────────────────┤
│ while (true) {                       │
│   conn = accept()                    │
│   create_thread(handle_client, conn) │
│ }                                    │
└──────────────────────────────────────┘
        ↓ создает            ↓ создает
┌─────────────────┐  ┌─────────────────┐
│ Рабочий поток 1 │  │ Рабочий поток 2 │
├─────────────────┤  ├─────────────────┤
│ handle_client() │  │ handle_client() │
│  для клиента 1  │  │  для клиента 2  │
│ (обработка...)  │  │ (обработка...)  │
└─────────────────┘  └─────────────────┘
        ↓ может создавать еще потоки...
```

**Работа:**
1. Главный поток работает в цикле
2. Для каждого входящего соединения создается новый рабочий поток
3. Рабочий поток обрабатывает запрос клиента независимо
4. Главный поток продолжает принимать новые соединения

**Характеристики:**
- **Преимущества:** 
  - Каждый клиент обслуживается параллельно
  - Хорошая масштабируемость до определенного числа потоков
  - Использование многоядерных систем
  - Быстрое реагирование на новые запросы
  
- **Недостатки:**
  - Создание потока требует ресурсов (стек, контекст)
  - Переключение контекста между потоками вызывает накладные расходы
  - При большом числе одновременных клиентов производительность падает

### Сравнительная таблица

| Аспект | Однопоточный | Многопоточный |
|--------|-------------|----------------|
| Количество обслуживаемых клиентов одновременно | 1 (последовательно) | Несколько параллельно |
| Задержка ответа для клиентов | Высокая (ждут в очереди) | Низкая (обрабатываются параллельно) |
| Использование многоядерности | Нет (одно ядро) | Да (распределение по ядрам) |
| Сложность реализации | Простая | Средняя (синхронизация) |
| Потребление памяти | Минимальное | Большое (стеки потоков) |

---

## Вопрос 15. Причины создания потоков. Объекты, относящиеся к процессам и потокам. Стратегии реализации потоков (плюсы и минусы каждого подхода)

### Объекты, относящиеся к процессам

**Процесс-уровень ресурсы (Process Control Block - PCB):**

| Объект | Описание |
|--------|---------|
| **Адресное пространство** | Память (стек, куча, сегменты кода и данных), доступная всему процессу |
| **Дескрипторы файлов** | Открытые файлы, каналы, сокеты (общие для всех потоков) |
| **Переменные окружения** | PATH, HOME, LC_ALL и прочие (наследуются потоками) |
| **PID (Process ID)** | Уникальный идентификатор процесса |
| **PPID (Parent PID)** | ID родительского процесса |
| **Сигналы** | Обработчики сигналов (SIGTERM, SIGKILL и т.д.) |
| **Приоритет и расписание** | Базовый приоритет процесса |
| **Ресурсы** | Лимиты памяти, лимиты открытых файлов (через ulimit) |
| **Таблица трансляции страниц** | Преобразование виртуальных адресов в физические (общее для всех потоков) |

### Объекты, относящиеся к потокам

**Поток-уровень ресурсы (Thread Control Block - TCB):**

| Объект | Описание |
|--------|---------|
| **TID (Thread ID)** | Уникальный идентификатор потока внутри процесса |
| **Собственный стек** | Каждый поток имеет независимый стек для локальных переменных и адресов возврата |
| **Регистры процессора** | EIP/RIP (указатель инструкций), RSP (указатель стека), другие регистры |
| **Состояние потока** | READY, RUNNING, BLOCKED, TERMINATED |
| **Локальное хранилище потока** | Thread Local Storage (TLS) для переменных, специфичных для потока |
| **Маска сигналов** | Какие сигналы заблокированы для конкретного потока |
| **Приоритет потока** | Динамический приоритет для планирования |
| **Контекст синхронизации** | Мьютексы и семафоры, удерживаемые потоком |

### Стратегии реализации потоков

#### 1. **ULT (User-Level Threads) — Потоки на уровне пользователя**

**Архитектура:**
```
Пользовательское пространство          Ядро операционной системы
┌────────────────────────────┐         ┌──────────────┐
│  Приложение + библиотека   │         │   Процесс    │
│  пользовательских потоков  │◄────────┤   (Ядро ОС)  │
│  (pthread, например)       │         │              │
│                            │         └──────────────┘
│  Потоки:                   │
│  ┌──────────┬──────────┐  │
│  │ Поток 1  │ Поток 2  │  │  (Видны только приложению,
│  │ Поток 3  │ Поток 4  │  │   ядро ОС видит только
│  └──────────┴──────────┘  │    один процесс)
│                            │
│  Планировщик потоков       │
│  (Управляется библиотекой) │
└────────────────────────────┘
```

**Характеристики:**
- Потоки создаются и управляются полностью в пользовательском пространстве
- Ядро операционной системы не знает о существовании потоков (видит только процесс)
- Переключение между потоками происходит в пользовательском пространстве без привлечения ядра
- Каждый поток имеет свой TCB в пользовательской памяти

**Преимущества ULT:**
- ✅ **Быстрое переключение контекста** — не требуется переключение в режим ядра (нет trap/exception)
- ✅ **Минимальные накладные расходы** — переключение — это просто сохранение и восстановление регистров
- ✅ **Простая реализация** — библиотека полностью контролирует планирование
- ✅ **Переносимость** — можно реализовать на любой ОС без поддержки потоков в ядре
- ✅ **Гибкость** — можно использовать кастомные алгоритмы планирования

**Недостатки ULT:**
- ❌ **Блокирование всего процесса** — если один поток выполняет блокирующий системный вызов (read, write), блокируется весь процесс и все его потоки
- ❌ **Отсутствие истинного параллелизма** — потоки не могут работать параллельно на многоядерных системах, они выполняются на одном ядре поочередно
- ❌ **Проблемы с планировщиком ОС** — ОС планирует процесс целиком, не учитывая приоритеты потоков внутри
- ❌ **Сложность синхронизации** — требуется внимательная работа с сигналами и блокировками

**Пример кода:**
```c
// ULT - пользовательские потоки (например, реализация в своей библиотеке)
struct thread {
    void *stack;
    struct context {
        long rip, rsp, rbx, r12, r13, r14, r15;
    } ctx;
};

void thread_yield() {
    // Сохранить текущий контекст
    // Выбрать следующий готовый поток
    // Восстановить его контекст
    // Нет системного вызова!
}
```

#### 2. **KLT (Kernel-Level Threads) — Потоки на уровне ядра**

**Архитектура:**
```
Пользовательское пространство          Ядро операционной системы
┌────────────────────────────┐         ┌──────────────────────┐
│  Приложение               │         │   Ядро ОС            │
│                            │         │                      │
│  Потоки (системные вызовы) │────────►│  ┌────────────────┐  │
│  для создания потоков      │         │  │ Процесс        │  │
│                            │         │  ├────────────────┤  │
│  Пользовательское TCB      │         │  │ Поток 1 (TCB)  │  │
│                            │         │  │ Поток 2 (TCB)  │  │
└────────────────────────────┘         │  │ Поток 3 (TCB)  │  │
                                       │  └────────────────┘  │
                                       │  Планировщик ядра    │
                                       │  (управляет всеми    │
                                       │   потоками в системе)│
                                       └──────────────────────┘
```

**Характеристики:**
- Ядро операционной системы полностью осведомлено о потоках
- Каждый поток имеет собственный TCB в ядре
- Планирование потоков осуществляется планировщиком ядра
- Переключение контекста требует перехода в режим ядра

**Преимущества KLT:**
- ✅ **Истинный параллелизм** — потоки могут выполняться параллельно на разных ядрах
- ✅ **Не блокирует другие потоки** — если один поток выполняет блокирующий системный вызов, другие потоки продолжают работу
- ✅ **Справедливое планирование** — ядро может планировать каждый поток независимо, учитывая его приоритет
- ✅ **Поддержка многопроцессорности** — полная поддержка SMP (Symmetric Multi-Processing)
- ✅ **Улучшенная обработка прерываний** — прерывания могут быть доставлены конкретному потоку

**Недостатки KLT:**
- ❌ **Дорогое переключение контекста** — требуется trap в ядро, переключение режима, синхронизация кэша
- ❌ **Большие накладные расходы на создание** — каждый системный вызов для создания потока требует ресурсов ядра
- ❌ **Ограничение на количество потоков** — ресурсы ядра ограничены (TCB, стеки ядра)
- ❌ **Сложность синхронизации в ядре** — ядро должно иметь механизмы синхронизации для защиты своих структур данных

**Пример использования:**
```c
// KLT - создание системного потока в Linux
#include <pthread.h>

void *thread_func(void *arg) {
    // Системный вызов: этот код выполняется в контексте потока
    // Ядро знает об этом потоке и может планировать его
    return NULL;
}

int main() {
    pthread_t tid;
    pthread_create(&tid, NULL, thread_func, NULL);  // Системный вызов
    pthread_join(tid, NULL);                         // Системный вызов
}
```

#### 3. **Гибридная модель (Hybrid Model) — M:N потоки**

**Архитектура:**
```
Пользовательское пространство          Ядро операционной системы
┌────────────────────────────┐         ┌──────────────────────┐
│  Приложение               │         │   Ядро ОС            │
│                            │         │                      │
│  M пользовательских потоков│────────►│  N системных потоков │
│  (управляется библиотекой) │         │  (управляются ядром) │
│                            │         │                      │
│  ┌──┬──┬──┬──┬──┐         │         │  ┌──┬──┬──┐        │
│  │U1│U2│U3│U4│U5│         │         │  │K1│K2│K3│        │
│  └──┴──┴──┴──┴──┘         │         │  └──┴──┴──┘        │
│  (M > N, например)        │         │  (ядро видит N)    │
└────────────────────────────┘         └──────────────────────┘
```

**Характеристики:**
- M пользовательских потоков мультиплексируются на N системных потоках
- Библиотека потоков управляет пользовательскими потоками и распределяет их на системные потоки
- Ядро управляет системными потоками
- Попытка найти компромисс между эффективностью ULT и мощью KLT

**Преимущества гибридной модели:**
- ✅ **Эффективность переключения контекста** — переключение между пользовательскими потоками происходит без привлечения ядра
- ✅ **Параллелизм на многоядерных системах** — системные потоки выполняются параллельно на разных ядрах
- ✅ **Не блокирует все потоки** — блокирование одного пользовательского потока не блокирует других, если они привязаны к разным системным потокам
- ✅ **Гибкая адаптация** — библиотека может динамически создавать/уничтожать системные потоки в зависимости от нагрузки

**Недостатки гибридной модели:**
- ❌ **Сложность реализации** — требуется сложная логика мультиплексирования
- ❌ **Проблема "holdup"** — если пользовательский поток заблокируется и задержит системный поток, это повлияет на другие потоки, мультиплексируемые на этот системный поток
- ❌ **Непредсказуемость** — поведение зависит от взаимодействия пользовательской библиотеки и ядра

### Сравнительная таблица стратегий реализации потоков

| Критерий | ULT | KLT | Гибридная |
|----------|-----|-----|-----------|
| **Контекст переключения** | Быстро (нет trap) | Медленно (через ядро) | Быстро для ULT, ядро для KLT |
| **Параллелизм на многоядерности** | Нет (одно ядро) | Да (все ядра) | Да (зависит от KLT) |
| **Блокирование при syscall** | Блокирует весь процесс | Только один поток | Зависит от распределения |
| **Количество потоков** | Много (тысячи) | Ограничено (сотни) | Гибкое (тысячи) |
| **Справедливость планирования** | Может быть несправедливо | Справедливо | Справедливо на уровне KLT |
| **Сложность реализации** | Простая | Сложная (в ядре) | Сложная (гибридизм) |
| **Кэширование отношений** | Плохо | Хорошо | Хорошо |

---

## Вопрос 16. Параллельное программирование. Fork-and-Join модель

### Что такое Fork-and-Join?

**Fork-and-Join** — это модель параллельного программирования, которая разделяет вычисления на подзадачи, выполняет их параллельно, а затем объединяет результаты.

```
Исходная задача
       │
       ├──► Fork (разделение на подзадачи)
       │
       ├──────────────────────┬────────────┬──────────┐
       │                      │            │          │
       ▼                      ▼            ▼          ▼
   Подзадача 1          Подзадача 2   Подзадача 3  Подзадача 4
   (Поток 1)            (Поток 2)     (Поток 3)    (Поток 4)
   
   Выполняются параллельно на разных ядрах
   
       │                      │            │          │
       └──────────────────────┴────────────┴──────────┘
       │
       ├──► Join (объединение результатов)
       │
       ▼
   Итоговый результат
```

### Принцип работы

**1. Fork (Расщепление):**
- Главный поток порождает дочерние потоки или подпроцессы
- Каждый подпоток/подпроцесс получает часть работы
- Подпотоки начинают выполняться параллельно

**2. Параллельное выполнение:**
- Подпотоки работают независимо друг от друга
- Каждый решает свою подзадачу
- На многопроцессорных системах они выполняются истинно параллельно

**3. Join (Объединение):**
- Главный поток ждет завершения всех подпотоков
- После завершения всех потоков результаты объединяются
- Главный поток продолжает работу с полным результатом

### Практический пример: Параллельный поиск максимума

```c
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>

typedef struct {
    int *data;      // Указатель на массив
    int start;      // Начальный индекс
    int end;        // Конечный индекс
    int max;        // Результат (максимум в диапазоне)
} task_t;

void *find_max(void *arg) {
    task_t *task = (task_t *)arg;
    task->max = task->data[task->start];
    
    for (int i = task->start + 1; i < task->end; i++) {
        if (task->data[i] > task->max) {
            task->max = task->data[i];
        }
    }
    return NULL;
}

int parallel_find_max(int *data, int size, int num_threads) {
    pthread_t threads[num_threads];
    task_t tasks[num_threads];
    
    // FORK: создание потоков
    int chunk = size / num_threads;
    for (int i = 0; i < num_threads; i++) {
        tasks[i].data = data;
        tasks[i].start = i * chunk;
        tasks[i].end = (i == num_threads - 1) ? size : (i + 1) * chunk;
        
        pthread_create(&threads[i], NULL, find_max, &tasks[i]);
    }
    
    // JOIN: ожидание завершения всех потоков
    int global_max = INT_MIN;
    for (int i = 0; i < num_threads; i++) {
        pthread_join(threads[i], NULL);
        if (tasks[i].max > global_max) {
            global_max = tasks[i].max;
        }
    }
    
    return global_max;
}
```

### Анализ производительности: Закон Амдала

Fork-and-Join производительность ограничена **законом Амдала**:

```
S = 1 / (f + (1-f)/p)

Где:
- S — ускорение (speedup)
- f — доля последовательного кода (0 ≤ f ≤ 1)
- p — количество процессоров/ядер
- (1-f) — доля параллелизуемого кода
```

**Примеры:**

| Доля параллельного кода | p=2 ядра | p=4 ядра | p=8 ядер |
|------------------------|----------|----------|-----------|
| 100% параллельно (f=0) | S=2.0    | S=4.0    | S=8.0     |
| 90% параллельно (f=0.1) | S=1.82   | S=3.08   | S=4.71    |
| 50% параллельно (f=0.5) | S=1.33   | S=1.60   | S=1.78    |
| 10% параллельно (f=0.9) | S=1.05   | S=1.09   | S=1.11    |

**Вывод:** Даже малая доля последовательного кода серьезно ограничивает ускорение.

### Когда использовать Fork-and-Join?

**Подходит для:**
- ✅ Разделяй и властвуй (divide and conquer) алгоритмы
- ✅ Параллельная сортировка (merge sort, quick sort)
- ✅ Поиск в больших структурах данных
- ✅ Вычисления на матрицах
- ✅ Рекурсивные алгоритмы

**Не подходит для:**
- ❌ Задачи с интенсивной синхронизацией
- ❌ Задачи с частыми обращениями к общим данным
- ❌ Задачи с очень высокой долей последовательного кода

---

## Вопрос 17. Параллельное программирование. Понятие псевдопараллелизма

### Определение

**Псевдопараллелизм (Pseudo-parallelism)** — это иллюзия параллельного выполнения множества потоков на системе с одним процессором (одним ядром), которая достигается за счет быстрого переключения контекста между потоками.

### Как это работает?

```
Система с одним ядром:

Шаг 1: Выполнить Поток 1 (100 мс)  ┐
Шаг 2: Выполнить Поток 2 (100 мс)  │ Планировщик ОС
Шаг 3: Выполнить Поток 3 (100 мс)  ├─► Переключение контекста
Шаг 4: Выполнить Поток 1 (100 мс)  │
Шаг 5: Выполнить Поток 2 (100 мс)  │
Шаг 6: Выполнить Поток 3 (100 мс)  ┘
...

Временная диаграмма:
─────────────────────────────────────────────────────────►Время

Поток 1: ██████        ██████        ██████
Поток 2:       ██████        ██████        ██████
Поток 3:             ██████        ██████        ██████

Ядро:   |████████████|████████████|████████████|
        Переключение контекста происходит каждые ~100мс
```

### Механизм достижения иллюзии параллелизма

**Компоненты:**

1. **Планировщик потоков (Thread Scheduler)**
   - Выбирает, какой поток выполнять на ядре в каждый момент времени
   - Использует алгоритмы: Round-Robin, Priority-based, Multi-level feedback queue

2. **Переключение контекста (Context Switch)**
   - Сохраняет состояние текущего потока (регистры, PC, SP)
   - Восстанавливает состояние следующего потока
   - Планировщик вызывается:
     - По таймеру (time-slice exhausted)
     - При блокирующем системном вызове
     - При добровольном переключении (yield)

3. **Иллюзия одновременности**
   - Поскольку переключение происходит быстро (тысячи раз в секунду)
   - Кажется, что потоки выполняются одновременно
   - На самом деле они выполняются по очереди

### Пример: Три потока на одном ядре

```c
#include <pthread.h>
#include <stdio.h>
#include <unistd.h>

void *thread_work(void *arg) {
    int id = *(int *)arg;
    for (int i = 0; i < 5; i++) {
        printf("Поток %d, итерация %d\n", id, i);
        usleep(100000);  // 100 мс
    }
    return NULL;
}

int main() {
    pthread_t t1, t2, t3;
    int id1 = 1, id2 = 2, id3 = 3;
    
    pthread_create(&t1, NULL, thread_work, &id1);
    pthread_create(&t2, NULL, thread_work, &id2);
    pthread_create(&t3, NULL, thread_work, &id3);
    
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    pthread_join(t3, NULL);
    
    return 0;
}

// Возможный вывод (или другой порядок — зависит от планировщика):
// Поток 1, итерация 0
// Поток 2, итерация 0
// Поток 3, итерация 0
// Поток 1, итерация 1
// Поток 2, итерация 1
// Поток 3, итерация 1
// ...
```

### Различие между псевдопараллелизмом и истинным параллелизмом

| Аспект | Псевдопараллелизм | Истинный параллелизм |
|--------|-------------------|----------------------|
| **Количество ядер** | 1 ядро | 2+ ядра |
| **Физическое одновременное выполнение** | Нет (очередь) | Да (на разных ядрах) |
| **Сложность синхронизации** | Меньше проблем (переключение контекста) | Больше проблем (истинная одновременность) |
| **Чередование инструкций** | Предсказуемо (на границах операций) | Непредсказуемо (в любой момент) |
| **Производительность** | Улучшается за счет перекрытия I/O | Значительно улучшается |

### Практическое значение понимания псевдопараллелизма

**Почему это важно:**

1. **Отсутствие гарантий атомарности на однопроцессорных системах**
   - Переключение контекста может произойти в любой момент между инструкциями
   - Даже простые операции могут быть не атомарными

2. **Ошибки видны на многопроцессорных системах**
   - Код может работать на одном ядре (псевдопараллелизм маскирует ошибки)
   - Но падает на многоядерных системах (истинный параллелизм выявляет race conditions)

3. **Необходимость синхронизации**
   - Даже на однопроцессорных системах нужна синхронизация
   - Потому что переключение контекста может произойти в критических местах

**Пример проблемы:**
```c
volatile int counter = 0;  // Общая переменная

void *increment(void *arg) {
    for (int i = 0; i < 1000; i++) {
        counter++;  // НЕ АТОМАРНО!
        // На ассемблере это: MOV EAX, [counter]
        //                     INC EAX
        //                     MOV [counter], EAX
        // Переключение контекста может произойти между этими инструкциями!
    }
}

// На однопроцессорной системе может случайно пройти (редко срабатывает)
// На многоядерной системе почти наверняка будет race condition
```

---

## Вопрос 18. Параллельное программирование. Ошибки в параллельном программировании. Гонка данных

### Основные ошибки в параллельном программировании

#### 1. **Гонка данных (Data Race)**

**Определение:** Гонка данных возникает, когда два или более потока получают доступ к одной и той же переменной, по крайней мере одно из этих обращений — это запись, и нет синхронизации между этими обращениями.

**Общая форма:**
```
Поток 1:                    Поток 2:
┌──────────────┐           ┌──────────────┐
│ Чтение x     │           │              │
│ (операция A) │           │              │
├──────────────┤           ├──────────────┤
│              │◄──────────►│ Запись x     │
│              │ RACE!      │ (операция B) │
├──────────────┤           ├──────────────┤
│ Использование│           │              │
│ значения x   │           │              │
└──────────────┘           └──────────────┘

Результат зависит от того, какая операция выполнится первой!
```

**Классификация:**

| Тип | Описание | Пример |
|-----|---------|--------|
| **Read-Write race** | Один поток читает, другой пишет | Один читает x, другой пишет x |
| **Write-Write race** | Несколько потоков пишут | Оба потока пишут в x |
| **Read-Read race** (редко) | Несколько потоков читают (обычно безопасно) | Оба потока читают x (нет проблем) |

**Пример кода с гонкой данных:**

```c
#include <pthread.h>
#include <stdio.h>

int counter = 0;  // Общая переменная — DANGER!

void *increment(void *arg) {
    for (int i = 0; i < 100000; i++) {
        counter++;  // ❌ RACE CONDITION!
    }
    return NULL;
}

int main() {
    pthread_t t1, t2;
    
    pthread_create(&t1, NULL, increment, NULL);
    pthread_create(&t2, NULL, increment, NULL);
    
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    
    printf("counter = %d (ожидаем 200000, но получим < 200000)\n", counter);
    
    return 0;
}

// Почему проблема?
// counter++ это не одна атомарная операция!
// На ассемблере это:
//   MOV EAX, [counter]      # Прочитать counter в EAX
//   INC EAX                 # Увеличить EAX
//   MOV [counter], EAX      # Записать EAX в counter
//
// Сценарий гонки:
// Поток 1: MOV EAX, [counter]  → EAX=5
// Поток 2: MOV EAX, [counter]  → EAX=5 (同時に!)
// Поток 1: INC EAX              → EAX=6
// Поток 2: INC EAX              → EAX=6
// Поток 1: MOV [counter], EAX   → counter=6
// Поток 2: MOV [counter], EAX   → counter=6 (перезаписал!)
// 
// Результат: counter=6 вместо ожидаемого 7
```

**Как избежать:**

```c
#include <pthread.h>
#include <stdio.h>

int counter = 0;
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

void *increment(void *arg) {
    for (int i = 0; i < 100000; i++) {
        pthread_mutex_lock(&lock);    // ✅ Защита!
        counter++;                     // Теперь это критическая секция
        pthread_mutex_unlock(&lock);
    }
    return NULL;
}

int main() {
    pthread_t t1, t2;
    
    pthread_create(&t1, NULL, increment, NULL);
    pthread_create(&t2, NULL, increment, NULL);
    
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    
    printf("counter = %d (теперь будет 200000)\n", counter);
    
    return 0;
}
```

#### 2. **Deadlock (Взаимная блокировка)**

**Определение:** Deadlock возникает, когда два или более потока взаимно ждут друг друга и не могут продолжить работу.

**Условия возникновения (необходимы все 4):**
1. **Mutual Exclusion** — ресурс не может использоваться одновременно
2. **Hold and Wait** — процесс держит ресурс и ждет другой
3. **No Preemption** — ресурсы не могут быть отняты
4. **Circular Wait** — циклическая цепь ожидания

**Пример (классический):**

```c
#include <pthread.h>
#include <stdio.h>
#include <unistd.h>

pthread_mutex_t lock1 = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t lock2 = PTHREAD_MUTEX_INITIALIZER;

void *thread1_func(void *arg) {
    printf("Поток 1: ждет lock1...\n");
    pthread_mutex_lock(&lock1);
    printf("Поток 1: получил lock1\n");
    
    sleep(1);  // Дать время потоку 2
    
    printf("Поток 1: ждет lock2...\n");
    pthread_mutex_lock(&lock2);  // ❌ DEADLOCK! Поток 2 уже ждет lock1
    printf("Поток 1: получил lock2\n");
    
    pthread_mutex_unlock(&lock2);
    pthread_mutex_unlock(&lock1);
    return NULL;
}

void *thread2_func(void *arg) {
    printf("Поток 2: ждет lock2...\n");
    pthread_mutex_lock(&lock2);
    printf("Поток 2: получил lock2\n");
    
    printf("Поток 2: ждет lock1...\n");
    pthread_mutex_lock(&lock1);  // ❌ DEADLOCK! Поток 1 уже ждет lock2
    printf("Поток 2: получил lock1\n");
    
    pthread_mutex_unlock(&lock1);
    pthread_mutex_unlock(&lock2);
    return NULL;
}

int main() {
    pthread_t t1, t2;
    
    pthread_create(&t1, NULL, thread1_func, NULL);
    pthread_create(&t2, NULL, thread2_func, NULL);
    
    pthread_join(t1, NULL);  // ❌ Никогда не завершится!
    pthread_join(t2, NULL);
    
    return 0;
}

// ВЫХОД: Deadlock!
// Поток 1: получил lock1, ждет lock2 (поток 2 его держит)
// Поток 2: получил lock2, ждет lock1 (поток 1 его держит)
// Бесконечное ожидание!
```

**Как избежать:**

```c
// Решение 1: Всегда захватывать мьютексы в одном порядке
void *thread1_func(void *arg) {
    pthread_mutex_lock(&lock1);  // Сначала всегда lock1
    pthread_mutex_lock(&lock2);  // Потом lock2
    // критическая секция
    pthread_mutex_unlock(&lock2);
    pthread_mutex_unlock(&lock1);
}

void *thread2_func(void *arg) {
    pthread_mutex_lock(&lock1);  // ✅ Тот же порядок!
    pthread_mutex_lock(&lock2);
    // критическая секция
    pthread_mutex_unlock(&lock2);
    pthread_mutex_unlock(&lock1);
}

// Решение 2: Использовать timeout
void *thread1_func(void *arg) {
    struct timespec timeout;
    clock_gettime(CLOCK_REALTIME, &timeout);
    timeout.tv_sec += 1;  // timeout через 1 секунду
    
    if (pthread_mutex_timedlock(&lock1, &timeout) != 0) {
        fprintf(stderr, "Ошибка: timeout при захвате lock1\n");
        return NULL;
    }
    
    if (pthread_mutex_timedlock(&lock2, &timeout) != 0) {
        pthread_mutex_unlock(&lock1);
        fprintf(stderr, "Ошибка: timeout при захвате lock2\n");
        return NULL;
    }
    
    // критическая секция
    pthread_mutex_unlock(&lock2);
    pthread_mutex_unlock(&lock1);
}
```

#### 3. **Livelock (Живая блокировка)**

**Определение:** Потоки активны, но не могут прогрессировать в своей работе. Они постоянно занимаются "безполезной работой".

**Пример:**

```c
volatile int flag = 0;

void *thread1_func(void *arg) {
    while (true) {
        flag = 1;
        if (flag == 2) break;
        // Если flag поменялся на 2 (поток 2 сделал свое)
        // мы выходим. Если нет — повторяем
    }
    printf("Поток 1 завершился\n");
}

void *thread2_func(void *arg) {
    while (true) {
        flag = 2;
        if (flag == 1) break;
        // Если flag поменялся на 1 (поток 1 сделал свое)
        // мы выходим. Если нет — повторяем
    }
    printf("Поток 2 завершился\n");
}

// Оба потока активны и работают, но не продвигаются!
// Они зацикливаются, постоянно перезаписывая flag друг друга
```

#### 4. **Starvation (Голодание потока)**

**Определение:** Поток готов к работе, но планировщик никогда не дает ему время на процессоре.

**Пример:**

```c
// Поток с высоким приоритетом постоянно работает
void *high_priority_thread(void *arg) {
    while (true) {
        // Бесконечно работаю
        for (int i = 0; i < 1000000; i++);
    }
    return NULL;
}

// Поток с низким приоритетом никогда не запустится
void *low_priority_thread(void *arg) {
    printf("Я никогда не выполнюсь!\n");  // Это никогда не выведется
    return NULL;
}

// Как избежать: явно вызывать yield() или sleep()
void *high_priority_thread_fixed(void *arg) {
    while (true) {
        for (int i = 0; i < 1000000; i++);
        sched_yield();  // ✅ Даем шанс другим потокам
    }
    return NULL;
}
```

#### 5. **Priority Inversion (Инверсия приоритетов)**

**Определение:** Поток с низким приоритетом держит ресурс (мьютекс), необходимый потоку с высоким приоритетом, который вынужден ждать.

**Пример:**

```
Время ──────────────────────────►

Высокий приоритет:  Готов    Ждет мьютекса    Ждет    Выполняется
(Real-time поток)    │         │               │        │
                    ─┴─────────┴───────────────┴────────┴─
                         ^                    ^
                    Хочет мьютекс          Получил
                    (он занят)             мьютекс

Нормальный приоритет: Выполняется (держит мьютекс)
(обычный поток)      ─────────────────────────────────
                          ↑
                     Блокирует ВП поток!
```

**Как избежать:** Использовать protocol наследования приоритетов в мьютексе.

### Сводная таблица типичных ошибок

| Ошибка | Описание | Признаки | Решение |
|--------|---------|----------|---------|
| **Data Race** | Несинхронизованный доступ к общим данным | Непредсказуемые результаты | Мьютексы, атомарные переменные |
| **Deadlock** | Циклическое взаимное ожидание | Программа зависает | Сортировка захватов, timeout |
| **Livelock** | Активная работа без прогресса | Потоки работают, но зациклены | Синхронизация, избежать spin-loops |
| **Starvation** | Поток не получает ресурсы | Поток готов, но не выполняется | Fair scheduling, yield() |
| **Priority Inversion** | Низкий приоритет блокирует высокий | Высокий приоритет не выполняется | Наследование приоритетов |

### Инструменты обнаружения гонок данных

**ThreadSanitizer (Google)**
```bash
gcc -fsanitize=thread -g program.c -o program -lpthread
./program
# Обнаружит data races в runtime
```

**Helgrind (Valgrind)**
```bash
valgrind --tool=helgrind ./program
# Анализирует синхронизацию потоков
```

**Потрошитель: Manual inspection**
```c
// Проверить:
// 1. Все общие переменные защищены мьютексами
// 2. Мьютексы захватываются в одном порядке
// 3. Нет бесконечных циклов без переключений контекста
// 4. Есть timeout для блокирующих операций
```

---

## Заключение

Понимание потоков критически важно для современного параллельного программирования. Ключевые моменты:

1. **Потоки создаются** для повышения модульности, производительности и реагирования на события
2. **Реализация потоков** может быть ULT, KLT или гибридной, каждая имеет свои плюсы и минусы
3. **Fork-and-Join** — мощная модель для параллелизуемых алгоритмов с ограничением закона Амдала
4. **Псевдопараллелизм** — это переключение контекста на однопроцессорных системах, создающее иллюзию параллелизма
5. **Ошибки в параллельном коде** (race conditions, deadlocks и т.д.) требуют тщательной синхронизации

Успешное параллельное программирование требует глубокого понимания этих концепций и аккуратной работы с синхронизацией.
